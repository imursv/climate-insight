"""AI ë¸Œë¦¬í•‘ ìƒì„± ëª¨ë“ˆ

Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ë“¤ì„ ì¢…í•©í•˜ì—¬
ëŒ€ë³€ì¸ ìŠ¤íƒ€ì¼ì˜ ë¸Œë¦¬í•‘ì„ ìƒì„±í•©ë‹ˆë‹¤.

2ë‹¨ê³„ ì²˜ë¦¬ ë°©ì‹:
1. ë°°ì¹˜ë³„ ê¸°ì‚¬ ìš”ì•½ (10ê°œì”©)
2. ìš”ì•½ ê¸°ë°˜ ì¢…í•© ë¸Œë¦¬í•‘ ìƒì„±
"""
import json
import re
from dataclasses import dataclass
from datetime import datetime
from typing import Literal

from .gemini_client import GeminiClient
from .news_processor import ProcessedNews
from ..utils.logger import get_logger

logger = get_logger(__name__)


@dataclass
class BriefingSection:
    """ë¸Œë¦¬í•‘ ì„¹ì…˜"""
    title: str
    content: str  # ì¸ìš© ë²ˆí˜¸ [1], [2] í¬í•¨
    tone: Literal["urgent", "positive", "neutral"]


@dataclass
class BriefingContent:
    """AI ìƒì„± ë¸Œë¦¬í•‘ ë‚´ìš©"""
    opening: str
    sections: list[BriefingSection]
    closing: str


@dataclass
class DailyBriefing:
    """ì¼ì¼ ë¸Œë¦¬í•‘ ë°ì´í„°"""
    date: str
    generated_at: str
    briefing: BriefingContent
    articles: list[dict]  # ëª¨ë“  ê¸°ì‚¬ (ë²ˆí˜¸ìˆœ)
    summary: dict


class BriefingGenerator:
    """ëŒ€ë³€ì¸ ìŠ¤íƒ€ì¼ ë¸Œë¦¬í•‘ ìƒì„±ê¸° (2ë‹¨ê³„ ì²˜ë¦¬)"""

    # ë°°ì¹˜ë‹¹ ê¸°ì‚¬ ìˆ˜
    BATCH_SIZE = 10

    # Phase 1: ë°°ì¹˜ë³„ ê¸°ì‚¬ ìš”ì•½ í”„ë¡¬í”„íŠ¸
    SUMMARY_BATCH_PROMPT = """ë‹¹ì‹ ì€ ê¸°í›„ë³€í™” ì „ë¬¸ ê³¼í•™ ì €ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•˜ì—¬ ê°ê° ìš”ì•½í•´ì£¼ì„¸ìš”.

## ìš”ì•½ ê·œì¹™
- phenomenon: ë¬´ì—‡ì´ ì¼ì–´ë‚¬ëŠ”ê°€? (êµ¬ì²´ì  ìˆ˜ì¹˜, ì§€ì—­, ì‹œì  í¬í•¨, 1-2ë¬¸ì¥)
- cause: ì™œ ì¼ì–´ë‚¬ëŠ”ê°€? (ê³¼í•™ì  ì›ì¸/ë°°ê²½, 1-2ë¬¸ì¥)
- outlook: ì•ìœ¼ë¡œ ì–´ë–»ê²Œ ë  ê²ƒì¸ê°€? (ì˜í–¥/ì „ë§, 1-2ë¬¸ì¥)
- **ì›ë¬¸ì— ëª…ì‹œë˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”. "ê¸°ì‚¬ì—ì„œ ì–¸ê¸‰ë˜ì§€ ì•ŠìŒ"ìœ¼ë¡œ í‘œê¸°**

## ê¸°ì‚¬ ëª©ë¡
{articles}

## ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ JSON)
{{
  "summaries": {{
    "{start_id}": {{"phenomenon": "...", "cause": "...", "outlook": "..."}},
    "{next_id}": {{"phenomenon": "...", "cause": "...", "outlook": "..."}}
  }}
}}"""

    # Phase 2: ì¢…í•© ë¸Œë¦¬í•‘ í”„ë¡¬í”„íŠ¸
    BRIEFING_PROMPT = """ë‹¹ì‹ ì€ ê¸°í›„ë³€í™” ì „ë¬¸ ëŒ€ë³€ì¸ì´ì ê³¼í•™ ì €ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ì˜¤ëŠ˜({date}) ìˆ˜ì§‘ëœ ê¸°í›„ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²©ì‹ìˆëŠ” ë°ì¼ë¦¬ ë¸Œë¦¬í•‘ì„ ì‘ì„±í•˜ì„¸ìš”.

## ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ ìš”ì•½ (ì´ {total_count}ê±´)
{summaries}

## ë¸Œë¦¬í•‘ ì‘ì„± ê·œì¹™

### 1. opening (ì˜¤í”„ë‹)
- ê²©ì‹ìˆëŠ” ì¸ì‚¬ë§ë¡œ ì‹œì‘
- ì˜ˆ: "ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ. {date} ê¸°í›„ ë¸Œë¦¬í•‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤."

### 2. sections (ë³¸ë¬¸ ì„¹ì…˜)
- **4-5ê°œ ì£¼ì œë³„ ì„¹ì…˜**ìœ¼ë¡œ êµ¬ì„±
- ê° ì„¹ì…˜ì€ **3-5ë¬¸ì¥**ìœ¼ë¡œ ì¶©ì‹¤í•˜ê²Œ ì‘ì„±
- **ë°˜ë“œì‹œ [ë²ˆí˜¸] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ ì¸ìš©** (ì˜ˆ: [1], [3, 5])
- ê´€ë ¨ ë‰´ìŠ¤ë“¤ì„ ì—°ê²°í•˜ì—¬ ë§¥ë½ê³¼ íë¦„ ì œê³µ
- titleì— ì´ëª¨ì§€ í¬í•¨:
  - ğŸ”´ ê¸´ê¸‰/ìœ„ê¸° ìƒí™©
  - ğŸŒ êµ­ì œ ë™í–¥
  - ğŸ‡°ğŸ‡· êµ­ë‚´ ì†Œì‹
  - âš ï¸ ê²½ê³ /ì£¼ì˜
  - ğŸŒ± ê¸ì •ì  ì§„ì „
- tone ê°’: "urgent"(ê¸´ê¸‰), "positive"(ê¸ì •), "neutral"(ì¤‘ë¦½)

### 3. closing (ë§ˆë¬´ë¦¬)
- ìš”ì•½ ë° ì „ë§ 1-2ë¬¸ì¥
- ì˜ˆ: "ì´ìƒìœ¼ë¡œ ì˜¤ëŠ˜ì˜ ê¸°í›„ ë¸Œë¦¬í•‘ì„ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤."

## ì¤‘ìš” ì‚¬í•­
- **ìœ„ ë‰´ìŠ¤ ìš”ì•½ì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©**í•˜ì„¸ìš”
- ìš”ì•½ì— ì—†ëŠ” ìˆ˜ì¹˜, ë‚ ì§œ, ê¸°ê´€ëª… ë“±ì„ ì„ì˜ë¡œ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”
- ëª¨ë“  ì •ë³´ëŠ” ë°˜ë“œì‹œ [ë²ˆí˜¸] ì¸ìš©ê³¼ í•¨ê»˜ ì‘ì„±

## ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ JSON)
{{
  "opening": "ê²©ì‹ìˆëŠ” ì˜¤í”„ë‹ ì¸ì‚¬",
  "sections": [
    {{
      "title": "ğŸ”´ ì„¹ì…˜ ì œëª©",
      "content": "ë³¸ë¬¸ ë‚´ìš©ì„ 3-5ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤ [1]. ê´€ë ¨ëœ ë‹¤ë¥¸ ë‰´ìŠ¤ì™€ ì—°ê²°í•˜ì—¬ ë§¥ë½ì„ ì œê³µí•©ë‹ˆë‹¤ [3, 5]. ì¶”ê°€ ì„¤ëª…ì„ ë§ë¶™ì…ë‹ˆë‹¤.",
      "tone": "urgent"
    }}
  ],
  "closing": "ë§ˆë¬´ë¦¬ ì¸ì‚¬"
}}"""

    def __init__(self, client: GeminiClient):
        self.client = client

    async def generate_briefing(
        self,
        processed_news: list[ProcessedNews],
        date: str | None = None
    ) -> DailyBriefing | None:
        """ì¼ì¼ ë¸Œë¦¬í•‘ ìƒì„± (2ë‹¨ê³„ ì²˜ë¦¬)

        Args:
            processed_news: ì²˜ë¦¬ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
            date: ë‚ ì§œ (YYYY-MM-DD), Noneì´ë©´ ì˜¤ëŠ˜

        Returns:
            ìƒì„±ëœ ë¸Œë¦¬í•‘ ë˜ëŠ” None
        """
        if not processed_news:
            logger.warning("ë¸Œë¦¬í•‘ ìƒì„±í•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None

        date = date or datetime.now().strftime("%Y-%m-%d")
        logger.info(f"=== ë¸Œë¦¬í•‘ ìƒì„± ì‹œì‘: {date}, {len(processed_news)}ê°œ ê¸°ì‚¬ ===")

        # Phase 1: ë°°ì¹˜ë³„ ê¸°ì‚¬ ìš”ì•½
        logger.info("Phase 1: ë°°ì¹˜ë³„ ê¸°ì‚¬ ìš”ì•½ ì‹œì‘")
        article_summaries = await self._summarize_in_batches(processed_news)
        logger.info(f"Phase 1 ì™„ë£Œ: {len(article_summaries)}ê°œ ê¸°ì‚¬ ìš”ì•½ë¨")

        # Phase 2: ì¢…í•© ë¸Œë¦¬í•‘ ìƒì„±
        logger.info("Phase 2: ì¢…í•© ë¸Œë¦¬í•‘ ìƒì„± ì‹œì‘")
        briefing_content = await self._generate_daily_briefing(
            processed_news, article_summaries, date
        )

        if not briefing_content:
            logger.error("Phase 2 ì‹¤íŒ¨: ë¸Œë¦¬í•‘ ìƒì„± ì‹¤íŒ¨")
            return None

        logger.info("Phase 2 ì™„ë£Œ: ë¸Œë¦¬í•‘ ìƒì„±ë¨")

        # ê¸°ì‚¬ ëª©ë¡ êµ¬ì„± (í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹)
        articles = self._format_articles_for_frontend(processed_news, article_summaries)

        # í†µê³„ ìš”ì•½
        summary = self._generate_summary(processed_news)

        return DailyBriefing(
            date=date,
            generated_at=datetime.now().isoformat(),
            briefing=briefing_content,
            articles=articles,
            summary=summary
        )

    async def _summarize_in_batches(
        self,
        news_list: list[ProcessedNews]
    ) -> dict[str, dict]:
        """ë°°ì¹˜ë³„ë¡œ ê¸°ì‚¬ ìš”ì•½ ìƒì„±

        Args:
            news_list: ì „ì²´ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸

        Returns:
            {ê¸°ì‚¬ë²ˆí˜¸: {phenomenon, cause, outlook}} ë”•ì…”ë„ˆë¦¬
        """
        all_summaries = {}
        total_batches = (len(news_list) + self.BATCH_SIZE - 1) // self.BATCH_SIZE

        for batch_idx in range(total_batches):
            start_idx = batch_idx * self.BATCH_SIZE
            end_idx = min(start_idx + self.BATCH_SIZE, len(news_list))
            batch = news_list[start_idx:end_idx]

            logger.info(f"ë°°ì¹˜ {batch_idx + 1}/{total_batches} ì²˜ë¦¬ ì¤‘ (ê¸°ì‚¬ {start_idx + 1}-{end_idx})")

            # ë°°ì¹˜ìš© ê¸°ì‚¬ ëª©ë¡ ìƒì„±
            articles_text = self._format_batch_articles(batch, start_idx + 1)

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.SUMMARY_BATCH_PROMPT.format(
                articles=articles_text,
                start_id=start_idx + 1,
                next_id=start_idx + 2
            )

            # Gemini í˜¸ì¶œ
            response = await self.client.generate(
                prompt,
                temperature=0.2,  # ì •í™•ì„±ì„ ìœ„í•´ ë‚®ê²Œ
                max_output_tokens=4000
            )

            if not response:
                logger.warning(f"ë°°ì¹˜ {batch_idx + 1} ìš”ì•½ ì‹¤íŒ¨: ì‘ë‹µ ì—†ìŒ")
                # ì‹¤íŒ¨í•œ ê¸°ì‚¬ë“¤ì— ëŒ€í•´ ê¸°ë³¸ ìš”ì•½ ìƒì„±
                for i, news in enumerate(batch):
                    article_id = str(start_idx + i + 1)
                    all_summaries[article_id] = self._get_default_summary(news)
                continue

            # JSON íŒŒì‹±
            batch_data = self._parse_json(response)
            if batch_data and "summaries" in batch_data:
                all_summaries.update(batch_data["summaries"])
                logger.debug(f"ë°°ì¹˜ {batch_idx + 1}: {len(batch_data['summaries'])}ê°œ ìš”ì•½ ì¶”ê°€")
            else:
                logger.warning(f"ë°°ì¹˜ {batch_idx + 1} JSON íŒŒì‹± ì‹¤íŒ¨")
                # ì‹¤íŒ¨í•œ ê¸°ì‚¬ë“¤ì— ëŒ€í•´ ê¸°ë³¸ ìš”ì•½ ìƒì„±
                for i, news in enumerate(batch):
                    article_id = str(start_idx + i + 1)
                    all_summaries[article_id] = self._get_default_summary(news)

        return all_summaries

    async def _generate_daily_briefing(
        self,
        news_list: list[ProcessedNews],
        article_summaries: dict[str, dict],
        date: str
    ) -> BriefingContent | None:
        """ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ì¢…í•© ë¸Œë¦¬í•‘ ìƒì„±

        Args:
            news_list: ì „ì²´ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
            article_summaries: ê¸°ì‚¬ë³„ ìš”ì•½
            date: ë¸Œë¦¬í•‘ ë‚ ì§œ

        Returns:
            BriefingContent ë˜ëŠ” None
        """
        # ìš”ì•½ ëª©ë¡ ìƒì„± (ì „ì²´ ê¸°ì‚¬ ì‚¬ìš©)
        summaries_text = self._format_summaries_for_briefing(news_list, article_summaries)

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.BRIEFING_PROMPT.format(
            date=date,
            total_count=len(news_list),
            summaries=summaries_text
        )

        # Gemini í˜¸ì¶œ (ì¶œë ¥ í† í° ì¶©ë¶„íˆ í™•ë³´ - Gemini 2.5 FlashëŠ” 65Kê¹Œì§€ ì§€ì›)
        response = await self.client.generate(
            prompt,
            temperature=0.7,  # ì°½ì˜ì„±ì„ ìœ„í•´ ì•½ê°„ ë†’ê²Œ
            max_output_tokens=32000  # ì¶©ë¶„í•œ ì¶œë ¥ í† í°
        )

        if not response:
            logger.error("ì¢…í•© ë¸Œë¦¬í•‘ ìƒì„± ì‹¤íŒ¨: ì‘ë‹µ ì—†ìŒ")
            return None

        # JSON íŒŒì‹±
        briefing_data = self._parse_json(response)
        if not briefing_data:
            logger.error(f"ì¢…í•© ë¸Œë¦¬í•‘ JSON íŒŒì‹± ì‹¤íŒ¨. ì‘ë‹µ ì‹œì‘: {response[:500]}")
            return None

        # BriefingContent êµ¬ì„±
        try:
            sections = [
                BriefingSection(
                    title=s.get("title", ""),
                    content=s.get("content", ""),
                    tone=s.get("tone", "neutral")
                )
                for s in briefing_data.get("sections", [])
            ]

            return BriefingContent(
                opening=briefing_data.get("opening", ""),
                sections=sections,
                closing=briefing_data.get("closing", "")
            )
        except Exception as e:
            logger.error(f"ë¸Œë¦¬í•‘ êµ¬ì¡°í™” ì‹¤íŒ¨: {e}")
            return None

    def _format_batch_articles(self, batch: list[ProcessedNews], start_id: int) -> str:
        """ë°°ì¹˜ìš© ê¸°ì‚¬ ëª©ë¡ í¬ë§·íŒ…"""
        lines = []
        for i, news in enumerate(batch):
            article_id = start_id + i
            article = news.article

            # ë²ˆì—­ëœ ì œëª© ì‚¬ìš©
            title = article.title
            if news.translation and news.translation.get("title_ko"):
                title = news.translation["title_ko"]

            # ë³¸ë¬¸ (ìš”ì•½ìš©)
            content = article.summary[:2000] if article.summary else ""

            lines.append(
                f"[{article_id}] ì œëª©: {title}\n"
                f"    ì¶œì²˜: {article.source} | ì–¸ì–´: {article.language}\n"
                f"    ë‚´ìš©: {content}"
            )

        return "\n\n".join(lines)

    def _format_summaries_for_briefing(
        self,
        news_list: list[ProcessedNews],
        article_summaries: dict[str, dict]
    ) -> str:
        """ë¸Œë¦¬í•‘ ìƒì„±ìš© ìš”ì•½ ëª©ë¡ í¬ë§·íŒ… (ê°„ê²°í•˜ê²Œ)"""
        lines = []
        for i, news in enumerate(news_list, 1):
            article = news.article
            summary = article_summaries.get(str(i), {})

            # ë²ˆì—­ëœ ì œëª© ì‚¬ìš©
            title = article.title
            if news.translation and news.translation.get("title_ko"):
                title = news.translation["title_ko"]

            # ê°ì„±
            sentiment = news.sentiment.get("sentiment", "neutral") if news.sentiment else "neutral"
            sentiment_emoji = {"positive": "ğŸŒ±", "negative": "âš ï¸", "neutral": "ğŸ“°"}.get(sentiment, "ğŸ“°")

            # ì¹´í…Œê³ ë¦¬
            category = "êµ­ë‚´" if article.language == "ko" else "êµ­ì œ"

            # í˜„ìƒë§Œ ì‚¬ìš© (ê°„ê²°í•˜ê²Œ)
            phenomenon = summary.get('phenomenon', 'ìš”ì•½ ì—†ìŒ')
            # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            if len(phenomenon) > 150:
                phenomenon = phenomenon[:147] + "..."

            lines.append(f"[{i}] {sentiment_emoji}[{category}] {title}: {phenomenon}")

        return "\n".join(lines)

    def _get_default_summary(self, news: ProcessedNews) -> dict:
        """ê¸°ë³¸ ìš”ì•½ ìƒì„± (API ì‹¤íŒ¨ ì‹œ)"""
        article = news.article
        return {
            "phenomenon": article.summary[:150] if article.summary else "ìš”ì•½ ì—†ìŒ",
            "cause": "ê¸°ì‚¬ì—ì„œ ì–¸ê¸‰ë˜ì§€ ì•ŠìŒ",
            "outlook": "ê¸°ì‚¬ì—ì„œ ì–¸ê¸‰ë˜ì§€ ì•ŠìŒ"
        }

    def _format_articles_for_frontend(
        self,
        news_list: list[ProcessedNews],
        article_summaries: dict[str, dict]
    ) -> list[dict]:
        """í”„ë¡ íŠ¸ì—”ë“œìš© ê¸°ì‚¬ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        articles = []
        for i, news in enumerate(news_list, 1):
            article = news.article
            sentiment = news.sentiment.get("sentiment", "neutral") if news.sentiment else "neutral"

            # ë²ˆì—­ëœ ì œëª© ì‚¬ìš©
            title = article.title
            original_title = None
            if news.translation and news.translation.get("title_ko"):
                original_title = article.title
                title = news.translation["title_ko"]

            # ìš”ì•½ ë°ì´í„°
            summary_data = article_summaries.get(str(i), self._get_default_summary(news))

            # í‚¤ì›Œë“œ
            keywords = []
            if news.keywords and news.keywords.get("keywords"):
                keywords = news.keywords["keywords"][:5]

            articles.append({
                "id": str(i),
                "title": title,
                "original_title": original_title,
                "url": article.link,
                "source": article.source,
                "published_at": article.published_at.isoformat() if article.published_at else "",
                "summary": summary_data,
                "sentiment": sentiment,
                "keywords": keywords,
                "language": article.language,
                "category": "domestic" if article.language == "ko" else "international"
            })

        return articles

    def _generate_summary(self, news_list: list[ProcessedNews]) -> dict:
        """í†µê³„ ìš”ì•½ ìƒì„±"""
        total = len(news_list)
        domestic = sum(1 for n in news_list if n.article.language == "ko")
        international = total - domestic

        sentiments = {"positive": 0, "negative": 0, "neutral": 0}
        all_keywords = []

        for news in news_list:
            if news.sentiment:
                s = news.sentiment.get("sentiment", "neutral")
                if s in sentiments:
                    sentiments[s] += 1

            if news.keywords and news.keywords.get("keywords"):
                all_keywords.extend(news.keywords["keywords"])

        # ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
        keyword_counts = {}
        for kw in all_keywords:
            keyword_counts[kw] = keyword_counts.get(kw, 0) + 1
        top_keywords = sorted(keyword_counts.keys(), key=lambda k: keyword_counts[k], reverse=True)[:5]

        return {
            "total_count": total,
            "domestic_count": domestic,
            "international_count": international,
            "top_keywords": top_keywords,
            "sentiment_breakdown": sentiments
        }

    def _parse_json(self, text: str | None) -> dict | None:
        """JSON ì‘ë‹µ íŒŒì‹± (ì˜ë¦° JSON ë³µêµ¬ ì‹œë„ í¬í•¨)"""
        if not text:
            return None

        try:
            # ```json ... ``` í˜•ì‹ ì²˜ë¦¬ (ë‹«íˆì§€ ì•Šì€ ê²½ìš°ë„ ì²˜ë¦¬)
            if "```json" in text:
                # ì‹œì‘ íƒœê·¸ ì´í›„ ë‚´ìš© ì¶”ì¶œ
                start_idx = text.find("```json") + 7
                end_idx = text.find("```", start_idx)
                if end_idx > start_idx:
                    text = text[start_idx:end_idx]
                else:
                    text = text[start_idx:]  # ë‹«íˆì§€ ì•Šì€ ê²½ìš° ëê¹Œì§€
            elif "```" in text:
                match = re.search(r"```\s*([\s\S]*?)(?:```|$)", text)
                if match:
                    text = match.group(1)

            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            match = re.search(r"\{[\s\S]*\}", text)
            if match:
                text = match.group(0)

            # ë¨¼ì € ì •ìƒ íŒŒì‹± ì‹œë„
            try:
                return json.loads(text)
            except json.JSONDecodeError:
                pass

            # ì˜ë¦° JSON ë³µêµ¬ ì‹œë„
            repaired = self._repair_truncated_json(text)
            if repaired:
                return json.loads(repaired)

            return None

        except json.JSONDecodeError as e:
            logger.debug(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.debug(f"ì›ë³¸ í…ìŠ¤íŠ¸: {text[:500]}")
            return None

    def _repair_truncated_json(self, text: str) -> str | None:
        """ì˜ë¦° JSON ë³µêµ¬ ì‹œë„"""
        if not text or not text.strip().startswith("{"):
            return None

        # ì—´ë¦° ê´„í˜¸ ì¹´ìš´íŠ¸
        open_braces = text.count("{") - text.count("}")
        open_brackets = text.count("[") - text.count("]")

        # ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´/ë°°ì—´ê¹Œì§€ ìë¥´ê¸°
        # ì˜ë¦° ë¬¸ìì—´ ë¶€ë¶„ ì œê±° (ë§ˆì§€ë§‰ ë¯¸ì™„ì„± ê°’)
        repaired = text.rstrip()

        # ë¯¸ì™„ì„± ë¬¸ìì—´ ì œê±° (í™€ìˆ˜ ê°œì˜ ë”°ì˜´í‘œ)
        quote_count = repaired.count('"') - repaired.count('\\"')
        if quote_count % 2 == 1:
            # ë§ˆì§€ë§‰ ë”°ì˜´í‘œ ì´ì „ê¹Œì§€ ìë¥´ê¸°
            last_quote = repaired.rfind('"')
            if last_quote > 0:
                repaired = repaired[:last_quote]
                # ë§ˆì§€ë§‰ í‚¤-ê°’ ìŒ ì œê±°
                last_colon = repaired.rfind(':')
                last_comma = repaired.rfind(',')
                cut_point = max(last_colon, last_comma)
                if cut_point > 0:
                    repaired = repaired[:cut_point]

        # ë‹«ëŠ” ê´„í˜¸ ì¶”ê°€
        repaired = repaired.rstrip(',: \n\t')
        repaired += "]" * open_brackets
        repaired += "}" * open_braces

        try:
            # ë³µêµ¬ëœ JSON ê²€ì¦
            json.loads(repaired)
            logger.info("ì˜ë¦° JSON ë³µêµ¬ ì„±ê³µ")
            return repaired
        except json.JSONDecodeError:
            logger.debug("JSON ë³µêµ¬ ì‹¤íŒ¨")
            return None

    def to_dict(self, briefing: DailyBriefing) -> dict:
        """DailyBriefingì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ dictë¡œ ë³€í™˜"""
        return {
            "date": briefing.date,
            "generated_at": briefing.generated_at,
            "briefing": {
                "opening": briefing.briefing.opening,
                "sections": [
                    {
                        "title": s.title,
                        "content": s.content,
                        "tone": s.tone
                    }
                    for s in briefing.briefing.sections
                ],
                "closing": briefing.briefing.closing
            },
            "articles": briefing.articles,
            "summary": briefing.summary
        }
